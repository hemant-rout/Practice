{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1951 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                      rotation_range = 20\n",
    "                                 )\n",
    "training_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (100, 100),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 106 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('test',\n",
    "                                            target_size = (100, 100),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = tf.keras.layers.Input(shape =(100,100,3))\n",
    "# inp1 = tf.keras.layers.Conv2D(32,padding='same',kernel_size=(3,3),kernel_initializer=tf.keras.initializers.he_normal())(inp1)\n",
    "# inp1 = tf.keras.layers.BatchNormalization()(inp1)\n",
    "# inp1 = tf.keras.layers.Activation('relu')(inp1)\n",
    "# inp1 = tf.keras.layers.Conv2D(32,padding='same',kernel_size=3,kernel_initializer=tf.keras.initializers.he_normal())(inp1)\n",
    "# inp1 = tf.keras.layers.BatchNormalization()(inp1)\n",
    "# inp1 = tf.keras.layers.Activation('relu')(inp1)\n",
    "# inp1 = tf.keras.layers.MaxPooling2D()(inp1)\n",
    "\n",
    "# inp1 = tf.keras.layers.Conv2D(64,padding='same',kernel_size=3,kernel_initializer=tf.keras.initializers.he_normal())(inp1)\n",
    "# inp1 = tf.keras.layers.BatchNormalization()(inp1)\n",
    "# inp1 = tf.keras.layers.Activation('relu')(inp1)\n",
    "# inp1 = tf.keras.layers.Conv2D(64,padding='same',kernel_size=3,kernel_initializer=tf.keras.initializers.he_normal())(inp1)\n",
    "# inp1 = tf.keras.layers.BatchNormalization()(inp1)\n",
    "# inp1 = tf.keras.layers.Activation('relu')(inp1)\n",
    "# inp1 = tf.keras.layers.MaxPooling2D()(inp1)\n",
    "\n",
    "# # inp = ks.layers.GlobalAveragePooling2D()(inp)\n",
    "# inp1 = tf.keras.layers.Flatten()(inp1)\n",
    "# inp1 = tf.keras.layers.Dense(256, activation='relu',kernel_initializer=tf.keras.initializers.he_normal())(inp1)\n",
    "# inp1 = tf.keras.layers.Dropout(0.5)(inp1)\n",
    "# inp1 = tf.keras.layers.Dense(80, activation='relu',kernel_initializer=tf.keras.initializers.he_normal())(inp1)\n",
    "# inp1 = tf.keras.layers.Dropout(0.5)(inp1)\n",
    "# inp1 = tf.keras.layers.Dense(4,activation='softmax',kernel_initializer=\"glorot_uniform\")(inp1)\n",
    "# model = tf.keras.models.Model(inputs =inp,outputs=inp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3,kernel_initializer=tf.keras.initializers.he_normal() \n",
    "                              , input_shape=[100, 100, 3]))\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "cnn.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3,kernel_initializer=tf.keras.initializers.he_normal() ))\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "cnn.add(tf.keras.layers.Activation('relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,padding=\"same\",kernel_size=3,kernel_initializer=tf.keras.initializers.he_normal()))\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "cnn.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,padding=\"same\",kernel_size=3,kernel_initializer=tf.keras.initializers.he_normal() ))\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "cnn.add(tf.keras.layers.Activation('relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128,padding=\"same\",kernel_size=3,kernel_initializer=tf.keras.initializers.he_normal()))\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "cnn.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128,padding=\"same\",kernel_size=3,kernel_initializer=tf.keras.initializers.he_normal() ))\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "cnn.add(tf.keras.layers.Activation('relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D())\n",
    "cnn.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "# # Adding a second convolutional layer\n",
    "# cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\n",
    "# cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# # Step 3 - Flattening\n",
    "# cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# # Step 4 - Full Connection\n",
    "# cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# Step 5 - Output Layer\n",
    "cnn.add(tf.keras.layers.Dense(units=4, activation='softmax',kernel_initializer=\"glorot_uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_105 (Conv2D)          (None, 100, 100, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 100, 100, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 100, 100, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 100, 100, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 50, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 50, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_14  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 289,316\n",
      "Trainable params: 288,420\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 61 steps, validate for 4 steps\n",
      "Epoch 1/100\n",
      "61/61 [==============================] - 28s 455ms/step - loss: 0.7206 - accuracy: 0.7186 - val_loss: 10.8909 - val_accuracy: 0.2358\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 21s 342ms/step - loss: 0.4643 - accuracy: 0.8165 - val_loss: 3.6615 - val_accuracy: 0.3962\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 16s 257ms/step - loss: 0.3637 - accuracy: 0.8580 - val_loss: 1.0611 - val_accuracy: 0.6415\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 16s 257ms/step - loss: 0.3048 - accuracy: 0.8919 - val_loss: 1.2940 - val_accuracy: 0.6415\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 16s 257ms/step - loss: 0.2679 - accuracy: 0.9001 - val_loss: 0.4682 - val_accuracy: 0.8208\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 16s 257ms/step - loss: 0.2496 - accuracy: 0.9113 - val_loss: 0.3720 - val_accuracy: 0.8302\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 16s 257ms/step - loss: 0.2137 - accuracy: 0.9200 - val_loss: 0.2325 - val_accuracy: 0.9151\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 16s 257ms/step - loss: 0.1922 - accuracy: 0.9303 - val_loss: 0.2836 - val_accuracy: 0.9057s\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 16s 256ms/step - loss: 0.2048 - accuracy: 0.9288 - val_loss: 1.6428 - val_accuracy: 0.6226\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 16s 257ms/step - loss: 0.1805 - accuracy: 0.9339 - val_loss: 0.4740 - val_accuracy: 0.8491\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 16s 256ms/step - loss: 0.1495 - accuracy: 0.9477 - val_loss: 0.1842 - val_accuracy: 0.9245\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 16s 257ms/step - loss: 0.1440 - accuracy: 0.9523 - val_loss: 0.8879 - val_accuracy: 0.7170  - ETA: 6s - loss: 0.1440 - accu - ETA: 0s - loss: 0.1423 - accuracy: \n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 16s 257ms/step - loss: 0.1243 - accuracy: 0.9600 - val_loss: 0.6963 - val_accuracy: 0.7642\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 16s 256ms/step - loss: 0.1224 - accuracy: 0.9590 - val_loss: 0.2177 - val_accuracy: 0.9245A - ETA: 2s - loss: 0.121\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 16s 255ms/step - loss: 0.1342 - accuracy: 0.9554 - val_loss: 0.4668 - val_accuracy: 0.8113 accuracy: 0.95 - ETA: 2s - loss: 0.1204 - accuracy - ETA: 2s - loss: 0.120\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 16s 258ms/step - loss: 0.1346 - accuracy: 0.9534 - val_loss: 1.9948 - val_accuracy: 0.6698\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 16s 258ms/step - loss: 0.1076 - accuracy: 0.9626 - val_loss: 0.0654 - val_accuracy: 0.99060.1073 - accuracy: 0.\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 16s 258ms/step - loss: 0.1082 - accuracy: 0.9631 - val_loss: 0.3702 - val_accuracy: 0.8491\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 16s 256ms/step - loss: 0.1015 - accuracy: 0.9677 - val_loss: 0.4290 - val_accuracy: 0.8396\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 16s 257ms/step - loss: 0.0907 - accuracy: 0.9708 - val_loss: 0.6279 - val_accuracy: 0.7170\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 16s 261ms/step - loss: 0.0944 - accuracy: 0.9692 - val_loss: 0.5931 - val_accuracy: 0.8396\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 16s 264ms/step - loss: 0.0820 - accuracy: 0.9723 - val_loss: 1.2421 - val_accuracy: 0.6226\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 16s 268ms/step - loss: 0.0793 - accuracy: 0.9780 - val_loss: 1.6093 - val_accuracy: 0.6226\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 16s 269ms/step - loss: 0.0893 - accuracy: 0.9728 - val_loss: 1.4557 - val_accuracy: 0.6226\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 16s 261ms/step - loss: 0.0742 - accuracy: 0.9764 - val_loss: 1.0081 - val_accuracy: 0.7736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19708611508>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Early_Stop = tf.keras.callbacks.EarlyStopping(patience=8,restore_best_weights=True)\n",
    "# Check_Point = tf.keras.callbacks.ModelCheckpoint('My_Model.h5', save_best_only=True)\n",
    "EarlyStopping = tf.keras.callbacks.EarlyStopping(patience=8,restore_best_weights=True)\n",
    "Check_Point = tf.keras.callbacks.ModelCheckpoint('My_Model.h5', save_best_weights=True)\n",
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 100,callbacks =[EarlyStopping,Check_Point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(cnn.history).plot(figsize=(8, 5))\n",
    "# plt.grid(True)\n",
    "# plt.gca().set_ylim(0, 1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_105 (Conv2D)          (None, 100, 100, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 100, 100, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 100, 100, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 100, 100, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 50, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 50, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_14  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 289,316\n",
      "Trainable params: 288,420\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('My_Model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9998164e-01, 7.5701823e-06, 7.3478391e-06, 3.3534000e-06]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('test/diseased cotton leaf/dis_leaf (175)_iaip.jpg', target_size = (100,100))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image=test_image/255\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1=model.predict_classes(test_image)\n",
    "class1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diseased cotton leaf': 0,\n",
       " 'diseased cotton plant': 1,\n",
       " 'fresh cotton leaf': 2,\n",
       " 'fresh cotton plant': 3}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (test_set.class_indices)\n",
    "label_map = dict((v,k) for k,v in label_map.items())\n",
    "pred = [label_map[k] for k in class1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diseased cotton leaf']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9998164e-01, 7.5701823e-06, 7.3478391e-06, 3.3534000e-06]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
